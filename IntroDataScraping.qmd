---
title: "Introduction to Web Scraping with R"
subtitle: "Chapter 24"
author: "Your Name Here"
format:
  html:
    toc: true
    toc_depth: 2
    number-sections: true
    number-depth: 2
    theme: yeti
execute: 
  warning: false
  cache: true
---

# Scraping Population Data from Wikipedia


Data on the web are often presented in tables. For instance, we can see a list of countries by population in 2000 on [Wikipedia](https://en.wikipedia.org/wiki/List_of_countries_by_population_in_2000)


Web pages are written in HTML (Hyper Text Markup Language) which uses **tags** to describe different aspects of document content. For example, a heading in a document is indicated by `<h1>My Title</h1>` whereas a paragraph would be indicated by `<p>A paragraph of content...</p>`. 


In this tutorial, we will learn how to read data from a table on a web page into R. We will need the package `rvest` to get the data from the web page, and the `stringr` package to clean up the data. We may also need  the `clean_names()` function from **janitor** to repair non-syntactic names.


```{r}
library(tidyverse)
library(rvest)
library(janitor)
```


## Reading data into R with `rvest`


To get the population data on [Wikipedia](https://en.wikipedia.org/wiki/List_of_countries_by_population_in_2000) into R, we can use the `read_html` command from the `xml2` package (which is attached when `rvest` is called) to parse the page to obtain an HTML document. 


We then use the `html_nodes` command that extracts all occurrences of the desired tag. We will be interested in scraping data presented in tables, so in the source code, we look for the table tag: `<table> ... </table>`.


Note: some of the `rvest` commands may be slow depending on your Internet connection and the complexity of the web page.


```{r}
popParse <- read_html("https://en.wikipedia.org/wiki/List_of_countries_by_population_in_2000")
str(popParse)
```


The `read_html` command creates an R object, basically a list, that stores information about the web page.


To extract a table from this web page:


```{r}
popNodes <- html_nodes(popParse, "table")
popNodes
```
There are several tables in this document. By inspecting the output of `popNodes`, we might make a guess that we want the third table. (Trial and error may be required.) We select the third table by using double brackets because we want the content of the 3rdh item from a list (more on R lists soon):


```{r}
pop <- html_table(popNodes, header = TRUE, fill = TRUE)[[3]]
str(pop) # take a look at the structure
```

##  Cleaning the data frame


We now have a workable data frame that we can clean using the tidyverse techniques we have been learning. Notice that all the variables have been read in as characters but we would typically regard rank and populations as numeric   For `Rank`, that is because the first observation is the world population and it is not assigned a rank, but rather, the character "-". The population column is seen as character because it contains commas and brackets. We need to clean up the data and convert these columns to be numeric.

Use **tidyverse** and **janitor**  commands to create a tidy data set called **popdata** that incorporates the following:
  * Removes the total world population row  
  * Syntactic names are converted to legal names
  * Character variable are converted to numeric where appropriate 
  * Special characters such as bracketed footnotes have been removed to simplify the appearance.
    + The following regular expression is very useful. Can you figure out what it finds and why you might want to replace it with a ""?
    ` "\\[[^]]+\\]" `
  
You should be able to do this in one continuous pipe but you should build up to it gradually by inspecting intermediate results. 

```{r}
df <- tibble(pop) |> 
  slice(-1) |>  
  clean_names() |> 
  rename(population = population2000estimate) |> 
  mutate(
    rank = parse_number(rank), 
    population = parse_number(population),
    country_territory = str_replace_all(country_territory, "\\[[^]]+\\]", "" )
    )
df
```


This approach depends on finding a highly structured table to scrape. An alternative approach described in R4DS and often more successful is making use of CSS selectors found in html documents that use of cascading style sheets (CSS).  The following examples illustrate this approach.





# A movie box office example


The web site [Box Office Mojo](http://www.boxofficemojo.com) gives statistics on box office earnings of movies. In addition to daily earnings, the web site also maintains lists of yearly and all time record holders.


We will look at the movies in the top 200 in all time movie worldwide grosses in box office receipts. In particular, we will scrape the data from [Box Office Mojo: All Time Box Office](http://www.boxofficemojo.com/alltime/world/?pagenum=1). The dollar amounts are in millions of dollars and the years marked with "^" indicate that the movie had multiple releases.


```{r}
movieParse<- read_html("https://www.boxofficemojo.com/chart/top_lifetime_gross/?area=XWW")

ranks <-
  movieParse |> 
  html_elements(".mojo-truncate") |> 
  html_text2() |> 
  parse_number()
  

titles <- 
  movieParse |> 
  html_elements(".mojo-field-type-title .a-link-normal") |> 
  html_text2()

gross <-
  movieParse |> 
  html_elements(".mojo-field-type-money") |> 
  html_text2() |>
  tail(-1) |>  # not quite a clean column
  parse_number()
  
year <-
  movieParse |> 
  html_elements(".mojo-field-type-year .a-link-normal") |> 
  html_text2() |> 
  parse_number()
```

Putting it all together in one pipe:

```{r}
moviedata <-
tibble(
  ranks =
    movieParse |> 
    html_elements(".mojo-truncate") |> 
    html_text2() |> 
    parse_number(),
  titles = 
    movieParse |> 
    html_elements(".mojo-field-type-title .a-link-normal") |> 
    html_text2(),
  gross =
    movieParse |> 
    html_elements(".mojo-field-type-money") |> 
    html_text2() |>
    tail(-1) |>  # not quite a clean column
    parse_number(),
  year =
    movieParse |> 
    html_elements(".mojo-field-type-year .a-link-normal") |> 
    html_text2() |> 
    parse_number()
)

str(moviedata)
```



#  On Your Own


The web site [NY Times Best Sellers: Hardcover Fiction](http://www.nytimes.com/books/best-sellers/hardcover-fiction) contains a list of best-selling fiction books. Scrape the names, authors, publishers, brief synopsis  and weeks on the list (`parse_number()`?) of these top books. Use SelectorGadget to obtain the appropriate css selector. 




# Resources

* [HTML Tutorial](www.w3schools.com)